This project aims to predict student performance based on various attributes such as gender, parental education level, and test preparation course status. It follows a structured approach with separate modules for each stage of the machine learning workflow, ensuring clarity and maintainability.

ML_Project/
â”œâ”€â”€ artifacts/                 # Stores generated artifacts like trained models and datasets
â”œâ”€â”€ data/                      # Contains the raw dataset (e.g., stud.csv)
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for exploratory data analysis
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/            # Core components: data ingestion, transformation, model training
â”‚   â”œâ”€â”€ exception.py           # Custom exception handling
â”‚   â”œâ”€â”€ logger.py              # Logging utility
â”‚   â””â”€â”€ utils.py               # Utility functions
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ setup.py                   # Package setup script
â””â”€â”€ README.md                  # Project documentation

ğŸ“Š Dataset
Source: data/stud.csv

Description: Contains student performance data with features like gender, parental education level, and test preparation course status.

ğŸ› ï¸ Installation
Clone the repository:

bash
git clone https://github.com/wildchaser1703/ML_Project.git
cd ML_Project


Create a virtual environment:
bash
python -m venv venv
source venv/bin/activate  
# On Windows: venv\Scripts\activate


Install dependencies:

bash
pip install -r requirements.txt

ğŸ“ˆ Usage
Data Ingestion:
bash
python src/components/data_ingestion.py
This script reads the raw data, performs train-test split, and saves the datasets in the artifacts/ directory.

Data Transformation:
bash
python src/components/data_transformation.py
Applies necessary preprocessing steps to the data.

Model Training:
bash
python src/components/model_trainer.py
Trains the machine learning model and saves it for future predictions.

ğŸ§ª Testing
To be added: Unit tests for each component to ensure reliability and correctness.

ğŸ“Œ Features
Modular codebase for scalability
Custom exception handling for better error tracking
Comprehensive logging for monitoring pipeline execution
Clear separation of concerns across different modules
